{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import sys\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv\n",
    "import time\n",
    "from numpy.linalg import inv\n",
    "from moviepy.editor import VideoFileClip\n",
    "from skimage.exposure import rescale_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistorth(img,mtx,dist):#function for un distorting the image wrt to camera parameters \n",
    "                             #obtained from camera calibration\n",
    "        h,w = img.shape[:2]\n",
    "        newcameramtx,roi=cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h)) \n",
    "        dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "        x,y,w,h = roi\n",
    "        dst = dst[y:y+h, x:x+w]\n",
    "        return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhancement(img):\n",
    "\n",
    "#-----Converting image to LAB Color model----------------------------------- \n",
    "    lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "#-----Splitting the LAB image to different channels-------------------------\n",
    "    l, a, b = cv2.split(lab)\n",
    "    #cv2.imshow('l_channel', l)\n",
    "    #cv2.imshow('a_channel', a)\n",
    "    #cv2.imshow('b_channel', b)\n",
    "\n",
    "#-----Applying CLAHE to L-channel-------------------------------------------\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "    #cv2.imshow('CLAHE output', cl)\n",
    "\n",
    "#-----Merge the CLAHE enhanced L-channel with the a and b channel-----------\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "    #cv2.imshow('limg', limg)\n",
    "\n",
    "#-----Converting image from LAB Color model to RGB model--------------------\n",
    "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    #cv2.imshow('final', final)\n",
    "    #cv2.waitKey()\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamicrange(image):\n",
    "    (iH, iW) = image.shape[:2]\n",
    "    Dl=image[:,:iW/2]\n",
    "    DR=image[:,iW/2:]\n",
    "    imagecopy2=np.zeros((iH,iW),dtype=\"uint8\")\n",
    "    for k in np.arange(0,iH):\n",
    "        maxv=np.max(Dl[k,:])\n",
    "        c=[i for i, j in enumerate(Dl[k,:]) if j == maxv]\n",
    "        if(len(c)):\n",
    "            imagecopy2[k][c[len(c)-1]]=Dl[k,c[len(c)-1]]\n",
    "        \n",
    "        maxvR=np.max(DR[k,:])\n",
    "        d=[m for m, n in enumerate(DR[k,:]) if n == maxvR]\n",
    "        if(len(d)):\n",
    "            imagecopy2[k][iW/2+d[0]]=DR[k,d[0]]\n",
    "    return imagecopy2\n",
    "            \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROI(img):   # function to get region of interest in a image\n",
    "    #img=color_filter(img1)\n",
    "    h=frame.shape[0]\n",
    "    w=frame.shape[1]\n",
    "    #change the ppoly coordinate according the camera mount\n",
    "    shape = np.array([[5,200 ],[w,200],[w, h],[5,h]])\n",
    "    #define a numpy array with the dimensions of img, but comprised of zeros\n",
    "    mask = np.zeros_like(img)\n",
    "    #Uses 3 channels or 1 channel for color depending on input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "    #creates a polygon with the mask color\n",
    "    cv2.fillPoly(mask, np.int32([shape]), ignore_mask_color)\n",
    "    #returns the image only where the mask pixels are not zero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def birdeyeview(frame):\n",
    "    h=frame.shape[0]\n",
    "    w=frame.shape[1]\n",
    "    pts1 = np.float32([[5,200 ],[w,200],[w, h],[5,h]])\n",
    "    pts2 = np.float32([[0, 0], [w, 0],[w,h],[0,h]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    result = cv2.warpPerspective(frame, matrix, (w,h))\n",
    "    return result,matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lanes_pixels(binary_warped):\n",
    "\n",
    "        # Take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "        #plt.plot(histogram)\n",
    "        #plt.show()\n",
    "        # Create an output image to draw on and  visualize the result\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set height of windows\n",
    "        window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated for each window\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 100\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix=50\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "            win_y_high = binary_warped.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "        return leftx, lefty, rightx, righty, left_lane_inds, right_lane_inds\n",
    "\n",
    "def poly_fit(leftx, lefty, rightx, righty, left_lane_inds, right_lane_inds, binary_warped, plot=False):  \n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        if(plot):\n",
    "            plt.imshow(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n",
    "            plt.plot(left_fitx, ploty, color='yellow')\n",
    "            plt.plot(right_fitx, ploty, color='yellow')\n",
    "            plt.xlim(0, 640)\n",
    "            plt.ylim(540, 0)\n",
    "            plt.show()\n",
    "\n",
    "        return left_fit, right_fit, ploty, left_fitx, right_fitx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_curvature(left_fit, right_fit, ploty, left_fitx, right_fitx, leftx, lefty, rightx, righty):\n",
    " \n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        ym_per_pix = float (30.0/720) # meters per pixel in y dimension\n",
    "        xm_per_pix = float (3.7/700 )# meters per pixel in x dimension\n",
    " \n",
    "        y_eval = np.max(ploty)\n",
    "        fit_cr_left = np.polyfit(ploty * ym_per_pix, left_fitx * xm_per_pix,2)\n",
    "        curverad_left = ((1 + (2 * left_fit[0] * y_eval / 2. + fit_cr_left[1]) ** 2) ** 1.5) / np.absolute(2 * fit_cr_left[0])\n",
    "        fit_cr_right = np.polyfit(ploty * ym_per_pix, right_fitx * xm_per_pix, 2)\n",
    "        curverad_right = ((1 + (2 * left_fit[0] * y_eval / 2. + fit_cr_right[1]) ** 2) ** 1.5) / np.absolute(2 * fit_cr_right[0])\n",
    "        return (curverad_left + curverad_right) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " def compute_center_offset(curverad, undist_image, plot=False):\n",
    "        xm_per_pix = 3.7/700\n",
    "        lane_center_x = int(curverad)\n",
    "        image_center_x = int(undist_image.shape[1] / 2)\n",
    "        offset_from_centre = (image_center_x - lane_center_x) * xm_per_pix # in meters\n",
    "        return offset_from_centre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plain_lane(undist, warped, M, left_fitx, right_fitx, ploty, plot=False):\n",
    "        \n",
    "        Minv = inv (M)\n",
    "\n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "        \n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "        \n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255,0))\n",
    "        \n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, Minv, (warped.shape[1], warped.shape[0])) \n",
    "        #newwarp=undistorth(newwarp)\n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "        if(plot):\n",
    "            plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " def render_curvature_and_offset(rundist_image, curverad, offset, plot=False):   \n",
    "        # Add curvature and offset information\n",
    "        offst_text = 'offset: {:.2f}m'.format(offset)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(rundist_image, offst_text, (24, 50), font, 1, (255, 255, 255), 2)\n",
    "        curverad_text = 'curverad: {:.2f}m'.format(curverad)\n",
    "        cv2.putText(rundist_image, curverad_text, (19, 90), font, 1, (255, 255, 255), 2)\n",
    "        if(plot):\n",
    "            plt.imshow(cv2.cvtColor(rundist_image, cv2.COLOR_BGR2RGB))\n",
    "        return rundist_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input = VideoFileClip(\"/home/karthik/Advance_lane_detection_code/pivideo11.mp4\")\n",
    "out = cv2.VideoWriter('outpyThresROIDday.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 25, (1210,440))\n",
    "#out1= cv2.VideoWriter(\"output.mp4\", fourcc, 25, (605,440), 0)\n",
    "for t in np.arange(1,17, 0.05): \n",
    "    frame=video_input.get_frame(t)\n",
    "    framek1=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    plot=False\n",
    "    mtx=np.loadtxt('/home/karthik/Downloads/opencv/camera_01/cameraMatrix.txt', delimiter=',', dtype=None)\n",
    "    dist=np.loadtxt('/home/karthik/Downloads/opencv/camera_01/cameraDistortion.txt', delimiter=',', dtype=None)\n",
    "    frame1=undistorth(framek1,mtx,dist)\n",
    "    frame11=enhancement(frame1)\n",
    "    lab= cv2.cvtColor(frame11, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    bitnotimage=cv2.bitwise_not(b)\n",
    "    diff=bitnotimage-b\n",
    "    diff[diff< 150] = 0\n",
    "    multipyimage=np.multiply(diff,b)\n",
    "    multipyimage[multipyimage<110] = 0\n",
    "    cL=dynamicrange(multipyimage)\n",
    "    ROIimage=ROI(cL)\n",
    "    BIEimage,matrix=birdeyeview(ROIimage)\n",
    "    leftx, lefty, rightx, righty, left_lane_inds, right_lane_inds=extract_lanes_pixels(BIEimage)\n",
    "    left_fit, right_fit, ploty, left_fitx, right_fitx=poly_fit( leftx, lefty, rightx, righty, left_lane_inds, right_lane_inds, BIEimage,plot)\n",
    "    curvature=compute_curvature(left_fit, right_fit, ploty, left_fitx, right_fitx, leftx, lefty, rightx, righty)\n",
    "    new_image=plain_lane(frame1, BIEimage, matrix, left_fitx, right_fitx, ploty, plot)\n",
    "    #inputinmage=new_image\n",
    "    offset_from_centre=compute_center_offset(curvature, new_image, plot)\n",
    "    Final_image=render_curvature_and_offset(new_image, curvature, offset_from_centre, plot)\n",
    "    cv2.imshow('new_image',new_image)\n",
    "    cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolve1(image):\n",
    "\n",
    "    # grab the spatial dimensions of the image, along with\n",
    "    # the spatial dimensions of the kernel\n",
    "    (iH, iW) = image.shape[:2]\n",
    "    Ml=np.array((\n",
    "    [-2, -3, 0],\n",
    "    [-3, 0, 3],\n",
    "    [0, 3, 2]), dtype=\"int\")\n",
    "   \n",
    "    Mr=np.array((\n",
    "    [0, 3, 2],\n",
    "    [-3, 0, 3],\n",
    "    [-2, -3, 0]), dtype=\"int\")\n",
    "    \n",
    "    (kH, kW) = Mr.shape[:2]\n",
    "    # allocate memory for the output image, taking care to\n",
    "    # \"pad\" the borders of the input image so the spatial\n",
    "    # size (i.e., width and height) are not reduced\n",
    "    pad = (kW - 1) // 2\n",
    "    image = cv2.copyMakeBorder(image, pad, pad, pad, pad,\n",
    "    cv2.BORDER_REPLICATE)\n",
    "    output = np.zeros((iH, iW), dtype=\"float32\")\n",
    "    for y in np.arange(pad, iH + pad):\n",
    "        for x in np.arange(pad, iW + pad):\n",
    "            # extract the ROI of the image by extracting the\n",
    "            # *center* region of the current (x, y)-coordinates\n",
    "            # dimensions\n",
    "            roi = image[y - pad:y + pad + 1, x - pad:x + pad + 1]\n",
    " \n",
    "            # perform the actual convolution by taking the\n",
    "            # element-wise multiplicate between the ROI and\n",
    "            # the kernel, then summing the matrix\n",
    "            if(x<iW/2):\n",
    "                k = (roi * Ml).sum()\n",
    "            else:\n",
    "                 k = (roi * Mr).sum()\n",
    "                \n",
    "            if(k<0):\n",
    "                k=0\n",
    "            # store the convolved value in the output (x,y)-\n",
    "            # coordinate of the output image\n",
    "            output[y - pad, x - pad] = k\n",
    "            # rescale the output image to be in the range [0, 255]\n",
    "    output = rescale_intensity(output, in_range=(0, 255))\n",
    "    output = (output * 255).astype(\"uint8\")\n",
    " \n",
    "\t# return the output image\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1-dev'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
